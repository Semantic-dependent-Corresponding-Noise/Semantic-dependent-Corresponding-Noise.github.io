<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Noise Datasets and Model Validation</title>
  
  <!-- Bulma CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap" rel="stylesheet">

  <style>
    :root {
      --primary-color: #8B0000;
      --text-main: #2c3e50;
      --bg-light: #f8f9fa;
    }

    body {
      font-family: 'Poppins', sans-serif;
      color: var(--text-main);
      /* 调整1: 字体大小回归标准，不再随宽度过度放大 */
      font-size: 1rem; 
      line-height: 1.6;
    }

    /* --- Typography --- */
    h1, h2, h3 { color: #000; }

    .hero-title {
      /* 调整2: 缩小主标题 */
      font-size: 2.25rem; 
      font-weight: 700;
      line-height: 1.2;
    }
    
    .hero-subtitle {
      /* 调整3: 缩小副标题 */
      font-size: 1.15rem;
      color: #4a4a4a;
      margin-top: 1rem;
      font-weight: 300;
      max-width: 800px;
      margin-left: auto;
      margin-right: auto;
    }

    .section-title {
      text-align: center;
      margin-bottom: 2rem; /* 减少间距 */
    }
    
    .section-title h2 {
      color: var(--primary-color);
      font-size: 1.75rem; /* 缩小章节标题 */
      font-weight: 600;
      position: relative;
      display: inline-block;
    }
    
    .section-title h2::after {
      content: '';
      display: block;
      width: 40px;
      height: 3px;
      background: var(--primary-color);
      margin: 8px auto 0;
      border-radius: 2px;
    }

    .content p, .content ul {
      text-align: justify; 
      margin-bottom: 1rem;
      font-size: 0.95rem; /* 正文稍微紧凑一点 */
    }

    /* --- Sections --- */
    .hero { 
      background-color: var(--bg-light); 
      padding: 3rem 1.5rem; /* 调整4: 减少 Hero 上下高度 */
    }
    
    .content-section { 
      padding: 2.5rem 0; /* 调整5: 减少各区块之间的留白 */
    }

    /* Table Styling */
    .table-container {
      box-shadow: 0 2px 8px rgba(0,0,0,0.05);
      border-radius: 8px;
      overflow: hidden;
      font-size: 0.9rem; /* 表格文字改小 */
    }
    .table thead th {
      background-color: var(--primary-color);
      color: white !important;
      font-weight: 600;
      padding: 0.75rem;
    }
    .table td {
      padding: 0.75rem;
      vertical-align: middle;
    }
    .table a {
      color: var(--primary-color);
      font-weight: 500;
      text-decoration: none;
    }
    .table a:hover {
      text-decoration: underline;
      color: #a52a2a;
    }

    /* --- Result Box --- */
    .result-section-wrapper {
      background-color: #f4f6f8;
    }
    
    .result-card {
      background: #fff;
      border-radius: 12px;
      padding: 1.5rem; /* 调整6: 减少卡片内边距 */
      margin-bottom: 2rem; 
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      border: 1px solid #eaeaea;
    }

    .result-header {
      font-size: 1.25rem; /* 缩小结果标题 */
      color: var(--primary-color);
      font-weight: 700;
      margin-bottom: 1rem;
      border-left: 4px solid var(--primary-color);
      padding-left: 12px;
    }

    .large-img-container {
      margin: 1rem 0;
      border-radius: 8px;
      overflow: hidden;
      border: 1px solid #eee;
      box-shadow: 0 2px 5px rgba(0,0,0,0.03);
    }
    
    .large-img-container img {
      width: 100%;
      height: auto;
      display: block;
    }
    
    /* 调整7: 优化图片说明样式，从“大标题”改为“小注脚” */
    .img-caption-tag {
      background: #f9f9f9;
      color: #555; 
      padding: 8px 12px; 
      font-size: 0.85rem; 
      font-weight: 500; 
      text-align: center;
      border-top: 1px solid #eee; /* 线条改到上方，因为caption通常在图下，或者是单独的块 */
      border-bottom: none;
    }

    /* 如果caption在图片上方，保持原逻辑但缩小 */
    .caption-top .img-caption-tag {
        border-bottom: 1px solid #eee;
        border-top: none;
    }

    .footer-section {
      background: #2c3e50;
      color: white;
      padding: 3rem 0 1.5rem;
      margin-top: 2rem;
    }

    /* Mobile Tweaks */
    @media (max-width: 768px) {
      .hero { padding: 2rem 1rem; }
      .hero-title { font-size: 1.8rem; }
      .result-card { padding: 1rem; }
    }
  </style>
</head>
<body>

  <!-- Hero Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title hero-title">
              <!-- 图标也稍微调小一点 -->
              <img src="assets/img/book.png" style="width:1em; vertical-align: bottom; margin-right: 8px;" alt="Logo"/>
              <span style="color: #8B0000;">Semantic-dependent-Corresponding-Noise</span>
            </h1>
            <h2 class="subtitle hero-subtitle">
              Introduce the first benchmark targeting semantic-dependent noisy correspondence to reveal the limitations of random-shuffling evaluations
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Introduction Section -->
  <section class="content-section">
    <div class="container is-max-desktop">
      <div class="section-title">
        <h2>Introduction</h2>
      </div>
      <div class="content">
        <p>
          Vision-Language Pre-training relies on webcrawled datasets that inherently contain noisy image-text correspondences. While Noisy Correspondence Learning (NCL) addresses this issue, evaluation typically relies on random shuffled datasets, which fails to capture the structured, semantic-dependent biases observed in real data. We introduce the first benchmark targeting semantic-dependent noisy correspondence. On Flickr30k and MS-COCO, we synthesize four systematic noise types, namely object omission, short description, entity referential error, and high-level semantic confusion. For the first three noise, we use large multimodal and language models to produce controlled perturbations via (i) constrained image re-description and (ii) targeted caption editing. For semantic confusion, we exploit cluster structure in representation space to select plausible but incorrect substitutes. Re-evaluating leading NCL methods on our datasets reveals distinct and diagnostic robustness patterns across noise types, demonstrating that semantic-dependent benchmarks expose challenges that random-shuffling evaluations miss.
        </p>
        
        <!-- 图片区域稍微收敛一点 -->
        <div style="max-width: 800px; margin: 2rem auto 0;">
            <figure class="image is-fullwidth large-img-container">
            <img src="assets/img/four_noise.png" alt="Noise Types">
            <div class="img-caption-tag">Figure 1: Framework for synthesizing structured semantic-dependent noise in image-text pairs.</div>
            </figure>
        </div>
      </div>
    </div>
  </section>

  <!-- Noise Datasets Table -->
  <section class="content-section" style="background-color: #fcfcfc;">
    <div class="container is-max-desktop">
      <div class="section-title">
        <h2>Noise Datasets</h2>
      </div>
      <div class="content">
        <p>
          The dataset directory contains folders for each type of noise applied to the MS-COCO and Flickr30K datasets. The noise types include:
        </p>
        <div class="columns">
            <div class="column is-6">
                <ul>
                <li><strong>Entity Referential Error</strong>: Incorrect references to entities.</li>
                <li><strong>High-level Semantic Confusion</strong>: Confusing high-level semantics.</li>
                </ul>
            </div>
            <div class="column is-6">
                <ul>
                <li><strong>Object Omission</strong>: Important objects omitted from captions.</li>
                <li><strong>Short Description</strong>: Incomplete or overly brief captions.</li>
                </ul>
            </div>
        </div>
        <p style="font-size: 0.9rem; color: #666; margin-top: -10px;">
          * Each type is available in two variants: <strong>5error</strong> (all five captions noisy) and <strong>Mixed</strong> (partially mixed).
        </p>
      </div>

      <div class="table-container">
        <table class="table is-fullwidth is-hoverable is-striped">
          <thead>
            <tr>
              <th style="width: 30%;">Dataset</th>
              <th>Flickr30k</th>
              <th>MS-COCO</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Object Omission</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Object_Omission_noise_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Object_Omission_noise_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
            <tr>
              <td>Object Omission (5error)</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Object_Omission_noise_5error_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Object_Omission_noise_5error_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
            <tr>
              <td>Short Description</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Short_Description_noise_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Short_Description_noise_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
            <tr>
              <td>Short Description (5error)</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Short_Description_noise_5error_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Short_Description_noise_5error_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
            <tr>
              <td>Entity Referential Error</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Entity_Referential_Error_noise_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Entity_Referential_Error_noise_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
            <tr>
              <td>Entity Referential Error (5error)</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Entity_Referential_Error_noise_5error_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/Entity_Referential_Error_noise_5error_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
            <tr>
              <td>High-level Semantic Confusion</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/High_level_Semantic_Confusion_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/High_level_Semantic_Confusion_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
            <tr>
              <td>High-level Semantic Confusion (5error)</td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/High_level_Semantic_Confusion_5error_f30k" target="_blank">Download (f30k)</a></td>
              <td><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise/tree/main/dataset/High_level_Semantic_Confusion_5error_MSCOCO" target="_blank">Download (COCO)</a></td>
            </tr>
          </tbody>
        </table>
        <p class="is-size-7 has-text-grey p-2">* Link text shortened for readability. Hover for details.</p>
      </div>
    </div>
  </section>

  <!-- Model Training Methodologies -->
  <section class="content-section">
    <div class="container is-max-desktop">
      <div class="section-title">
        <h2>Model Training Methodologies</h2>
      </div>
      <div class="content">
        <p>
          We validate the effectiveness of the noise datasets using three primary training strategies:
        </p>
        <ul>
          <li><strong>CLIP Pre-trained Model</strong>: Fine-tuning a pre-trained CLIP model to evaluate direct performance degradation under noisy conditions.</li>
          <li><strong>NPC (Noise Pre-training and Class-wise fine-tuning)</strong>: Pre-training on noisy datasets followed by class-wise fine-tuning to assess robustness.</li>
          <li><strong>GLP (Gradient-based Label Propagation)</strong>: Applying gradient-based label propagation to mitigate the effects of incorrect semantic alignments.</li>
        </ul>
      </div>
    </div>
  </section>

  <!-- Results Analysis Section (宽度调整) -->
  <section class="content-section result-section-wrapper">
    <!-- 调整8: 这里从 is-max-widescreen 改为 is-max-desktop，让图片和表格不要拉得太宽 -->
    <div class="container is-max-desktop">
      <div class="section-title">
        <h2>Results Analysis</h2>
      </div>
      
      <!-- Module 1: Robustness Comparison -->
      <div class="result-card">
        <h3 class="result-header">1. Robustness Comparison: NPC vs. CLIP</h3>
        
        <div class="content">
          <p>
            Our comparisons on <strong>Flickr30k</strong> and <strong>MS-COCO</strong> reveal that <strong>NPC</strong> outperforms <strong>CLIP</strong> in noise robustness. Compared to random shuffling (RS), NPC demonstrates significantly greater robustness under semantic noise (especially <strong>SD/SC</strong>), with this advantage increasing as the noise rate rises. 
          </p>
        </div>

        <div class="columns is-variable is-4">
          <div class="column is-half">
            <div class="large-img-container caption-top">
               <div class="img-caption-tag">Table 1: Retrieval metrics on Flickr30K (CLIP / NPC)</div>
               <img src="assets/img/table1.png" alt="Comparison Table on Flickr30k">
            </div>
          </div>
          <div class="column is-half">
            <div class="large-img-container caption-top">
               <div class="img-caption-tag">Table 2: Retrieval metrics on MSCOCO 5K (CLIP / NPC)</div>
               <img src="assets/img/table2.png" alt="Comparison Table on MS-COCO">
            </div>
          </div>
        </div>

        <div class="content is-size-7 has-text-grey">
          <p>
            * RS: Random Shuffle, OO: Object Omission, SD: Short Description, ER: Entity Referential Error, SC: Semantic Confusion.
          </p>
        </div>
        
        <div class="content">
          <p>
            Although object omission (<strong>OO</strong>) poses the most severe disruption, limiting NPC's improvement, the overall difficulty ranking (<strong>RS < SC≈SD < ER < OO</strong>) remains stable across datasets.
          </p>
        </div>
      </div>

      <!-- Module 2: Noise Impact & Bias -->
      <div class="result-card">
        <h3 class="result-header">2. Noise Impact on Model Behavior</h3>
        
        <div class="columns is-vcentered">
          <div class="column is-7">
            <div class="large-img-container" style="margin: 0;">
              <img src="assets/img/figure2.png" alt="Average Similarity Score Analysis">
            </div>
             <div class="img-caption-tag" style="border-top:none; border-bottom:none; background:transparent; text-align:left; padding-left:0;">
                <small><strong>Figure 2:</strong> Average Cross-Modal Similarity Scores of Noisily Trained Models.</small>
              </div>
          </div>
          
          <div class="column is-5">
            <div class="content">
              <p>
                To measure how noise during training shapes model behavior, we evaluate each noisily trained model by computing its average similarity score across pairs in corrupted test sets.
              </p>
              <p>
                The results reveal a consistent pattern: models trained on a specific type of noisy data tend to exhibit elevated similarity scores when evaluated on test sets with the same noise type. It shows that noisily trained models inherit the semantic biases of their training data.
              </p>
            </div>
          </div>
        </div>
      </div>

    </div>
  </section>

  <!-- Footer -->
  <footer class="footer-section">
    <div class="container is-max-desktop">
      <div class="columns">
        <div class="column is-half">
          <h3 style="color: #ff8b8b; font-size: 1.1rem; margin-bottom: 0.5rem;">Noise Datasets</h3>
          <p style="opacity: 0.8; font-size: 0.85rem;">Introduce the first benchmark targeting semantic-dependent noisy correspondence to reveal the limitations of random-shuffling evaluations</p>
        </div>
        <div class="column is-half has-text-right-tablet">
          <h4 style="color: #ff8b8b; margin-bottom: 0.5rem; font-size: 1rem;">Links</h4>
          <ul style="list-style: none; padding: 0;">
            <li style="margin-bottom: 0.5rem;"><a href="https://github.com/Semantic-dependent-Corresponding-Noise/Semantic-dependent-Corresponding-Noise" style="color: white; opacity: 0.8; text-decoration: none; font-size: 0.9rem;">GitHub Repository</a></li>
          </ul>
        </div>
      </div>
      <hr style="border-color: rgba(255,255,255,0.1); margin: 1.5rem 0 1rem;">
      <div class="has-text-centered">
        <p style="opacity: 0.6; font-size: 0.8rem;">&copy; 2025 Semantic-dependent-Corresponding-Noise. All Rights Reserved.</p>
      </div>
    </div>
  </footer>

  <!-- Scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
